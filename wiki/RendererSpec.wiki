The renderer is implemented using the deferred rendering technique. See docs/papers/rendering/deferred rendering for much information about this technique.

For the G-Buffer four RGBA8 Color-Attachments and one 32Bit Floating Depth-Attachment are used to deliver the necessary properties to the Lighting-Stage.

*Color-Attachment layouts*
  * 1.DiffuseR, DiffuseG, DiffuseB, MaterialType
  * 2.NormalX, NormalY, NormalZ, Specular-Component
  * 3.Generic
  * 4.Generic

==Material System==
Each material uses a special BRDF-model to simulate the lighting reflection.
Each material can specify a RGB triple as base-color ( can be used as single color without texturing over the whole object or as an ambient term when applying textures).
Each material can have applied none, one or up to four diffuse-color textures.
Each material can have a normal-map. When a normal-map is specified this will override the normals from the object.
Each material can have a specular.map. Some BRDFs will ignore this.
Transparent material is available but not implemented in the deferred rendering pass but in a separate one. Seee lighting & shadowing.

The material-type is also the BRDF-type. The following BRDFs are supported:
  * DIFFUSE – won't apply any lighting-calculations and use just the diffuse color. Looks shit and is very very cheap.
  * LAMBERTIAN – use the lambertian law to apply lighting. Looks better and is well suited for diffuse material which needs to have lighting applied. Very cheap
  * PHONG – uses the phong-model to apply lighting. Introduces specular highlights onto lambertian base color. Used for plastic or material with specular effects. Cheap.
  * ORENNAYAR – a more phyiscally plausible retro-diffuse BRDF than lambertian. Expensive.
  * SSS – does an approximation of subsurface scattering which can be used to render jade or porcelain. Very expensive.
  * WARDS – an implementation of wards brdf-model. Can simulate a huge amount of materials when the correct parameters are used. Very expensive.
  * TORRANCESPARROW – an implementation of the torrance-sparrow BRDF which uses a microfacet model. Can simulate a huge amount of materials when the correct parameters are used. Expensive.

Materialproperties of an object which change over the object need to be encoded in a texture e.g. normalmaps, diffuse color, specular component. Properties which stay constant for an entire object can be passed through the material uniform-block to the geometry-stage.

*Material-Definition examples*
Some woody floor. It's lambertian because no specular highligh needed and wood is diffuse but we want the lambertian light-model applied. No base-color specified because using textures as diffuse color.
{{{
<material name='WoodFloor'>
	<type='LAMBERTIAN'/>
		<diffuseColor1 = 'path/woodFloorBase.tga'/>
		<diffuseColor2 = 'path/woodFloorFine.tga'/>
		<normalMap = 'path/woodFloorNormals.tga'/>
	</type>
</material>
}}}

Some stone floor. It's phong because it has some specular sparkles in it. No base color specified because using textures as diffuse color.
{{{
<material name='StoneFloor'>
	<type='PHONG'/>
		<diffuseColor1 = 'path/stoneFloorBase.tga'/>
		<diffuseColor2 = 'path/stoneFloorFine.tga'/>
		<diffuseColor3 = 'path/stoneFloorGrain.tga'/>
		<specularMap = 'path/stoneFloorSpecularMap.tga'/>
		<normalMap = 'path/stoneFloorNormals.tga'/>
	</type>
</material>
}}}

Transparent Glass. 
{{{
<material name='ChurchGlass'>
	<type='TRANSPARENT'/>
		<diffuseColor1 = 'path/churchWindowColor.tga'/>
		<normalMap = 'path/churchWindowNormals.tga'/>
	</type>
</material>
}}}

Phong BRDF. Doesn't use any texture but just a base-color.
{{{
<material name='BluePlastic'>
	<type='PHONG'/>
		<color r='0.0' g='0.0' b='1.0'/>

		TODO: add parameters of this BRDF
	</type>
</material>
}}}

Oren-Nayar BRDF
{{{
<material name=“MatePaper“>
	<type=“ORENNAYAR“/>
		TODO: add parameters of this BRDF
	</type>
</material>
}}}

Subsurface Scattering Approximation BRDF
{{{
<material name=“Jade“>
	<type=“SSS“/>
		TODO: add parameters of this BRDF
	</type>
</material>
}}}

Wards BRDF
{{{
<material name=“BrushedMetal“>
	<type=“WARDS“/>
		TODO: add parameters of this BRDF
	</type>
</material>
}}}

Torrance-Sparrow Microfacet BRDF
{{{
<material name=“SnowMetal“>
	<type=“TORRANCESPARROW“/>
		TODO: add parameters of this BRDF
	</type>
</material>
}}}

The following Material-Types are defined (transparency not rendered with this mechanism)
  * DIFFUSE			0
  * LAMBERTIAN		1
  * PHONG			2
  * ORENNAYAR		3
  * SSS				4
  * WARDS			5
  * TORRANCESPARROW		6
  * TRANSPARENT		99 (special-case, won't be handled with deferred rendering directly)

The geometry-stage program could look like:
Fragment-Shader

{{{
#define MAX_DIFFUSE_TEXT 4

uniform block
{
	vec4 materialConfig; // x=materialtype, y=diffuseTextureCounter, z=normal map 0/1, w=specular map0/1
	vec4 genericMaterialAttrib1;	// written to ColorAttachment 3
	vec4 genericMaterialAttrib2;	// written to ColorAttachment 4

	vec4 materialColor;	// base-color of material

	sampler diffuseTextures[MAX_DIFFUSE_TEXT];
	sampler normalMap;
	sampler specularMap;
}

in vec2 ex_textureCoord;
in vec3 ex_normal;

out vec4 out_diffuse;
out vec4 out_normal;
out vec4 out_generic1;
out vec4 out_generic2;

void main()
{	
	// store materialtype in diffuse-component alpha-channel
	out_diffuse.a = materialConfig.x;

	// store base-color of material
	out_diffuse.rgb = materialColor.rgb;

	// multitexturing sums up each texture fetch
	// the number of textures for this material is stored in
	// materialConfig.y - component
	for ( int i = 0; i < materialConfig.y; i++ )
	{
		out_diffuse.rgb += texture( diffuseTextures[i], ex_textureCoord ).rgb;
	}

	// normal-mapping enabled – fetch from texture
	if ( 1.0 == materialConfig.z )
	{
		out_normal.xyz = texture( normalMap, ex_textureCoord ).xyz;
	}
	else
	{
		out_normal.xyz = ex_normal.xyz;
	}

	// set alpha component of normal o 0
	out_normal.a = 0.0;

	// specular-mapping enabled – fetch from texture and store
	// in normal alpha-component
	// specular-map should be a 1channel 8bit luminance map with 	// values between 0 – 255
	if ( 1.0 == materialConfig.w )
	{
		out_normal.a = texture( ex_textureCoord ).r;
	}

	out_generic1 = genericMaterialAttrib1;
	out_generic2 = genericMaterialAttrib2;
}
}}}

It is obvious that in this shader no distinction between the material type is done – no dynamic branching like if ( 0 == materialConfig.x ). This is because the configurations are set in a way that this is not necessary in the geometry-stage. 
Transparency is completely ignored in the geometry-buffer because deferred rendering is inherent unable to render transparency directly. For this purpose an additional non-deferred rendering stage needs to be applied after the lighting-stage. See lighting&shadowing for discussion of this stage.

*Lighting & Shadowing*
The renderer should support a theoretically unlimited number of shadow-casting lights of the following category.
  * Spotlight - perspective planar Shadow-Map
  * Directional-Light – orthographic planar Shadow-Map
  * Pointlight – perspective cube Shadow-Map

Each light can be configured individually.
  * Shadow-Caster YES/NO
  * Falloff – Spotlight & Pointlight only
  * FieldOfView – Spotlight only (Pointlight is 90° in all 6 directions both shadow & light)
  * Color

Fragment-Shader of Light-Stage
{{{
uniform sampler diffuseMap;
uniform sampler normalMap;
uniform sampler depthMap;
uniform sampler genericMap1;
uniform sampler genericMap2;

uniform shadowSampler shadowMap;
uniform shadowSamplerCube shadowCubeMap;

out vec4 final_color;

uniform block light_data
{
	vec4 lightConfig; // x: type, y: falloff, z: shadowCaster 0/1
	vec4 lightPosition;		// spot & point only
	vec4 lightDirection; 	// spot & directional only
	vec4 color;

	mat4 lightSpace;
	mat4 lightSpaceUniform;
}

void main()
{
	// fetch the coordinate of this fragment in normalized
	// screen-space ( 0 – 1 ) 
	vec2 screenCoord = ...;

	vec4 diffuse = texture( diffuseMap, screenCoord );
	vec4 normal = texture( normalMap, screenCoord );
	// stored as luminance floating point 32bit
	vec4 depth = texture( depthMap, screenCoord ).x;
	vec4 generic1 = texture( genericMap1, screenCoord );
	vec4 generic2 = texture( genericMap2, screenCoord );
	
	float shadow = 0.0f;

	// light is not a point light
	if ( 2 != lightConfig.x )
	{
		// get the world-coordinate of this fragment
		vec4 worldCoord = ...; // apply inverse projection-matrix and undo projection
		// transform the worldCoord into model-coordinates
		vec4 modelCoord = ...; // apply inverse view-matrix
		// get the fragment in the light-space
		vec4 lightCoord = ...; // apply the lightSpace-Matrix to the modelCoord
		// transform lightcoord to fit from NDC (lightSpace matrix includes viewing-projection) into the unit-cube 0-1 to be able to access the shadow-map
		vec4 shadowCoord = ...; // apply the unit-cube matrix

		// spot-light is projective – shadowlookup must be projective
		if ( 0 == lightConfig.x )
		{
			shadow = textureProj( shadowMap, shadowcoord );
		}
		// directional-light is orthographic – no projective shadowlookup
		else
		{
			shadow = texture( shadowMap, shadowcoord );
		}
	}
	// point-light shadow is handled with cube map
	else
	{
		// cube-map access is done through the world-space normal
		vec3 worldSpaceNormal = ...;
		shadow = texture( shadowCubeMap, worldSpaceNormal );
	}

	// this fragment is not in shadow, only then apply lighting
	if ( shadow == 0.0 )
	{
		if ( 0 == diffuse.a )
			renderDiffuseBRDF();
		else if ( 1 == diffuse.a )
			 renderLambertianBRDF();
		else if ( 2 == diffuse.a )
			 renderPhongBRDF();
		else if ( 3 == diffuse.a )
			 renderOrenNayarBRDF();
		else if ( 4 == diffuse.a )
			 renderSSSBRDF();
		else if ( 5 == diffuse.a )
			 renderWardsBRDF();
		else if ( 6 == diffuse.a )
			 renderMicrofacetBRDF();
		end if
	}
	else
	{
		// TODO: soft-shadows

		// when in shadow, only the diffuse color is used for
		// the final color output but darkened by its half
		final_color.rgb = diffuse.rgb * 0.5;
		final_color.a = 0.0;
	}
}

void renderDiffuseBRDF()
{
}

void renderLambertianBRDF()
{
}

void renderPhongBRDF()
{
}

void renderOrenNayarBRDF()
{
}

void renderSSSBRDF()
{
}

void renderWardsBRDF()
{
}

void renderMicrofacetBRDF()
{
}
}}}

The problem with transparent rendering are:
  * correct visibility
  * normal mapping
  * bring on screen

For correct visiblity we need to sort the transparent objects back to front and render them in this order. Visibility with the other objects in the scene needs to be considered too, so z-buffer needs to be utilized. For this the depth-map of the geometry-stage framebuffer can be used.
Things get complicated when we want to do normal mapping, which means the transparent object perturbes the background behind it by the use of its normals. For this to be possible the background needs to be accessed as a texture where the normals are used to offset the texture-coordinates.
For this to achieve we need the final composition of the lighting-stage in one texture, which can be achieved by rendering to an additional texture in the geometry-framebuffer (Color-Attachment 5).
It sounds funny but the lighting-stage will use the geometry-stage framebuffer (it is bound during the lighting-stage) to apply bounding-geometry of each light to the scene.
To bring the composition on screen we need another render-to-texture in the geometry-stage framebuffer because we bind the geometry-stage framebuffer for the depth-visibility of the transparent objects and so cannot write to the main framebuffer directly. For this purpose we can recycle an old buffer e.g. the diffuse color because it is needed no more and won't be accessed during rendering the final composition.
First all transparent objects are rendered in front-to-back with stencil turned on. The stenciling is necessary to prevent the filling of the rest of the scene to overdraw the transparent objects. Then with orthographic projection a screen-sized quad is drawn with the lighting-stage render-to-texture as texture. This will close the empty space around the transparent objects, where the stencil buffer will protect the already drawn transparent objects from overdraw.
To bring it on screen we render in orthographic projection a screen-sized quad with the final composition as texture into the main framebuffer.

With this technique we don't have light applied to transparent objects and transparent objects behind  other transparent objects are not recognized within the perturbations in the transparent object in front.

TODO: add opengl-steps and vertex&fragment shader for transparency-step

// optimization: when the main framebuffer is used (color-attachments go to aux-buffers) then we don't need this additional indirection in transparency rendering.
// is it possible to access the framebuffer in a shader?

==Modeling==
Supported model-formats
  * 3DS – 3D Studio
  * MS3D – Milkshape 3D
  * PLY -  Ply-Format (http://en.wikipedia.org/wiki/PLY_%28file_format%29)
  * TODO: OBJ – Obj-Format (http://en.wikipedia.org/wiki/Wavefront_.obj_file)

==Occlusion Culling==
  * View-Frustum culling – NDC culling of BoundingBoxes
  * Dynamic occlusion culling with occlusion queries – CHC++. The depth buffer of the G-Stage can be utilized for the occlusion queries.

==Nice to have==
  * SSAO
  * Planar Reflections
  * Dynamic Environment Reflections using cube-maps
  * Parallax Mapping

==Animation==
It is not planned to implement any kind of animations in this engine.